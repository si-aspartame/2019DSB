{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n  warnings.warn(msg, category=FutureWarning)\n"}],"source":["from IPython import get_ipython\n","import numpy as np\n","import pandas as pd\n","# pd.set_option('display.max_columns', 1000)\n","from tqdm import tqdm_notebook as tqdm\n","from collections import Counter\n","from scipy import stats\n","import lightgbm as lgb\n","# from sklearn.metrics import cohen_kappa_score\n","from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n","import gc\n","import json\n","from sklearn import metrics\n","from sklearn.preprocessing import LabelEncoder\n","from bayes_opt import BayesianOptimization\n","import lightgbm as lgb\n","from sklearn.metrics import cohen_kappa_score\n","\n","%matplotlib inline\n","\n","%load_ext autoreload\n","%autoreload 2\n","from DSB_func_ishikawa import *\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#・event_idは、あるユーザのあるゲームに対して一つ割り当てられる。\n","#  一度閉じてもevent_idは変更されない、game_sessionは変更される。\n","#・game_sessionは、ゲームの種別ごとの、毎回のプレイ(開いてから閉じるまで)に与えられるIDであり\n","#  一度閉じると同じユーザであっても変更される。\n","#・timestampはtimestampだがstring型なので変換が必要\n","#・event_dataは謎のjson\n","#・installation_idでユーザを区別している。\n","#・event_countはevent_dataから抽出されるゲームセッション内の増加値で、1が引かれている。\n","#・event_codeはそれぞれのtitleで固有のイベントの種類だが、2000は常にゲームスタートを表す。\n","#・game_timeはゲーム開始からの秒数(ms)\n","#・titleはゲームタイトル\n","#・typeはゲームまたはビデオのタイプ\n","#  'Game', 'Assessment(評価)', 'Activity(活動？)', 'Clip(ビデオクリップ？)'\n","#・worldはゲームやビデオが属するセクション、 \n","#  'NONE' (at the app's start screen), TREETOPCITY' (Length/Height),\n","#  'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight)\n","\n","# それぞれのinstallation_idの最後のAssesment群について、\n","# そのAssesmentが\n","# 3:最初のトライでtrue\n","# 2:二回目のトライでtrue\n","# 1:三回目以降のトライでtrue\n","# 0:正解できなかった\n","# を最終的に予測する\n","# そのためには最後のAssesmentの最終トライでcorrectがtrueかどうかを確認(num_correct)し\n","# その後、そのAssessment群でいくつ不正解したかを確認(num_incorrect)する。\n","# そこから最終的なAccuracy_groupを算出する\n","\n","# Bird MeasurerのAssessmentは二段階で、4100のあとに4110が続く。この場合予測するのは4110の方。\n","# 他は4100一回のみ\n","\n","#Assessmentとそれ以外で指標を分ける\n","\n","#全部横に並べて入れるか、最終try以前のデータから作った特徴量を付加した1行で予測をするか\n","#installation_idごとの最後のAssessment群\n","#今までのAssessmentのTrue回数\n","\n","#testデータのそれぞれのinstallation_idの最後のトランザクションは常に2000でAssessmentが始まる\n","#その結果を予測する\n","\n","#その子供が最後の2000で始まるAssessmentで良い結果を残すにはどういう条件が必要か\n","\n","#過去に同じAssessmentをプレイしている 0, 1\n","#過去に同じAssessmentでtrueである 0, 1\n","#今までのtransaction数\n","#今までのAssessmentのプレイ回数(gamessessionのうちAssessmentをカウント)\n","\n","#これまでのトランザクションのタイムスタンプ間の差の中央値＝速度\n","\n","#gamesessionで区切ると、閉じて再起動してすぐプレイしたときにバグる\n","#以前のもの全てで入れるしかない\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Loading\n"}],"source":["print('Loading')\n","train = pd.read_csv('./input/train.csv')\n","test = pd.read_csv('./input/test.csv')\n","labels = pd.read_csv('./input/train_labels.csv')\n","sub = pd.read_csv('./input/sample_submission.csv')\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"event_id           object\ngame_session       object\ntimestamp          object\nevent_data         object\ninstallation_id    object\nevent_count         int64\nevent_code          int64\ngame_time           int64\ntitle              object\ntype               object\nworld              object\ndtype: object\n['installation_id', 'game_session', 'event_id', 'squeeze_target', 'type', 'event_code', 'event_data', 'timestamp', 'date', 'game_time', 'event_count', 'game_session|installation_id', 'world']\n['game_session', 'installation_id', 'title', 'num_correct', 'num_incorrect', 'accuracy']\n"}],"source":["# train_df[(train_df['event_code']==4100) & (train_df['type'] == 'Assessment')]\n","dropping_in_data=[\n","    'installation_id','game_session', 'event_id', 'squeeze_target', \\\n","    'type', 'event_code', 'event_data', 'timestamp', 'date', \\\n","    'game_time', 'event_count', 'game_session|installation_id', 'world']\n","#correctとincorrectを予測したほうがいいかも\n","dropping_in_labels=['game_session','installation_id','title','num_correct','num_incorrect', 'accuracy']\n","print(train.dtypes)\n","print(dropping_in_data)\n","print(dropping_in_labels)\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"experienced_assessment:\n100%|██████████| 12629/12629 [01:03<00:00, 199.17it/s]\ntransforming is done!\n"}],"source":["new_train, new_test = transform(train, test)\n","if train['event_id'].all() == new_train['event_id'].all():\n","    print('transforming is done!')\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"data_squeeze:\n100%|██████████| 21239/21239 [01:14<00:00, 285.27it/s]\n"}],"source":["sq_new_train = data_squeeze(new_train,mode='train')\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["labels = pd.read_csv('./input/train_labels.csv')\n","labels['game_session|installation_id'] = labels['game_session'] +'|'+ labels['installation_id']\n","dropped_labels = labels.drop(columns=dropping_in_labels, axis=1)\n","\n","sq_new_train['game_session|installation_id'].head()\n","merged_sq_new_train = pd.merge(sq_new_train, dropped_labels, on='game_session|installation_id')\n","dropped_sq_new_train = merged_sq_new_train.drop(columns=dropping_in_data, axis=1)\n",""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>hour</th>\n      <th>exp_assess</th>\n      <th>accuracy_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17680</th>\n      <td>4</td>\n      <td>21</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17681</th>\n      <td>4</td>\n      <td>21</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17682</th>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17683</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17684</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17685</th>\n      <td>3</td>\n      <td>12</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17686</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17687</th>\n      <td>2</td>\n      <td>15</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17688</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17689</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       title  hour  exp_assess  accuracy_group\n17680      4    21           0               1\n17681      4    21           1               3\n17682      0    21           0               3\n17683      2     1           0               3\n17684      1     1           0               3\n17685      3    12           0               3\n17686      2     1           0               3\n17687      2    15           0               1\n17688      4     1           0               0\n17689      2     2           1               1"},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dropped_sq_new_train.tail(10)\n",""]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"data_squeeze:\ntest_squeeze:\n100%|██████████| 1000/1000 [00:02<00:00, 492.99it/s]\n"}],"source":["sq_new_test = data_squeeze(new_test, mode='test')\n","dropped_sq_new_test = sq_new_test.drop(columns=dropping_in_data, axis=1)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train = dropped_sq_new_train\n","test = dropped_sq_new_test\n",""]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":"1000"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(sub)\n","len(test)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Fold 1\n[100]\ttraining's multi_logloss: 1.13414\tvalid_1's multi_logloss: 1.14665\n[200]\ttraining's multi_logloss: 1.09864\tvalid_1's multi_logloss: 1.1197\n[300]\ttraining's multi_logloss: 1.08313\tvalid_1's multi_logloss: 1.11096\n[400]\ttraining's multi_logloss: 1.07481\tvalid_1's multi_logloss: 1.10786\n[500]\ttraining's multi_logloss: 1.07031\tvalid_1's multi_logloss: 1.10752\nFold 2\n[100]\ttraining's multi_logloss: 1.13595\tvalid_1's multi_logloss: 1.14189\n[200]\ttraining's multi_logloss: 1.10115\tvalid_1's multi_logloss: 1.11235\n[300]\ttraining's multi_logloss: 1.08586\tvalid_1's multi_logloss: 1.10173\n[400]\ttraining's multi_logloss: 1.07759\tvalid_1's multi_logloss: 1.09759\n[500]\ttraining's multi_logloss: 1.07272\tvalid_1's multi_logloss: 1.097\nFold 3\n[100]\ttraining's multi_logloss: 1.13487\tvalid_1's multi_logloss: 1.14501\n[200]\ttraining's multi_logloss: 1.0995\tvalid_1's multi_logloss: 1.11708\n[300]\ttraining's multi_logloss: 1.08392\tvalid_1's multi_logloss: 1.10674\n[400]\ttraining's multi_logloss: 1.07554\tvalid_1's multi_logloss: 1.10273\n[500]\ttraining's multi_logloss: 1.07108\tvalid_1's multi_logloss: 1.10205\nFold 4\n[100]\ttraining's multi_logloss: 1.13698\tvalid_1's multi_logloss: 1.13991\n[200]\ttraining's multi_logloss: 1.10275\tvalid_1's multi_logloss: 1.10825\n[300]\ttraining's multi_logloss: 1.08755\tvalid_1's multi_logloss: 1.09642\n[400]\ttraining's multi_logloss: 1.07928\tvalid_1's multi_logloss: 1.09133\n[500]\ttraining's multi_logloss: 1.07444\tvalid_1's multi_logloss: 1.08953\n[600]\ttraining's multi_logloss: 1.07117\tvalid_1's multi_logloss: 1.08954\nFold 5\n[100]\ttraining's multi_logloss: 1.13518\tvalid_1's multi_logloss: 1.1419\n[200]\ttraining's multi_logloss: 1.09998\tvalid_1's multi_logloss: 1.11349\n[300]\ttraining's multi_logloss: 1.08422\tvalid_1's multi_logloss: 1.10398\n[400]\ttraining's multi_logloss: 1.07554\tvalid_1's multi_logloss: 1.10063\nOur oof cohen kappa score is:  0.4235696950026957\n3    0.714189\n0    0.253703\n1    0.031995\n2    0.000113\ndtype: float64\ndone!\n"}],"source":["\n","usefull_features=['title', 'hour', 'exp_assess']\n","categoricals = ['title', 'hour']\n","def run_lgb(train, test, usefull_features):\n","    kf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n","    target = 'accuracy_group'\n","    oof_pred = np.zeros((len(train), 4))\n","    y_pred = np.zeros((len(test), 4))\n","    for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train[target])):\n","        print('Fold {}'.format(fold + 1))\n","        x_train, x_val = train[usefull_features].iloc[tr_ind], train[usefull_features].iloc[val_ind]\n","        y_train, y_val = train[target][tr_ind], train[target][val_ind]\n","        train_set = lgb.Dataset(x_train, y_train, categorical_feature=categoricals)\n","        val_set = lgb.Dataset(x_val, y_val, categorical_feature=categoricals)\n","\n","        params = {\n","            'learning_rate': 0.01,\n","            'metric': 'multiclass',\n","            'objective': 'multiclass',\n","            'num_classes': 4,\n","            'feature_fraction': 0.75,\n","            'subsample': 0.75,\n","            'n_jobs': -1,\n","            'seed': 50,\n","            'max_depth': 10\n","        }\n","\n","        model = lgb.train(params, train_set, num_boost_round = 1000000, early_stopping_rounds = 50, \n","                          valid_sets=[train_set, val_set], verbose_eval = 100)\n","        oof_pred[val_ind] = model.predict(x_val)\n","        y_pred += model.predict(test[usefull_features]) / 5\n","    loss_score = cohen_kappa_score(train[target], np.argmax(oof_pred, axis = 1), weights = 'quadratic')\n","    result = pd.Series(np.argmax(oof_pred, axis = 1))\n","    print('Our oof cohen kappa score is: ', loss_score)\n","    print(result.value_counts(normalize = True))\n","    return y_pred\n","prediction = run_lgb(train, test, usefull_features)\n","sub['accuracy_group'] = np.round(prediction).astype(int)\n","sub.to_csv('submission.csv', index = False)\n","print('done!')\n","\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}